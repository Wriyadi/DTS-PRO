{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirportTraffic_Tensorflow_Rizqon (US & AUS).ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import math\n",
        "from google.colab import drive #Mount Google Drive\n",
        "import timeit\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#from keras.callbacks import EarlyStopping\n",
        "from keras.layers import ConvLSTM2D"
      ],
      "metadata": {
        "id": "d14YJboyyy_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Y5-uEdumMsso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Membaca & modifikasi data traffic density USA & Australia\n",
        "dataset= pd.read_csv('/content/drive/MyDrive/covid_impact_on_airport_traffic.csv')\n",
        "\n",
        "#dataset_US = dataset[dataset['Country']=='United States of America (the)']\n",
        "#df_US = pd.DataFrame(dataset_US.groupby('Date',as_index=True)['PercentOfBaseline'].mean())\n",
        "#print(df_US)\n",
        "\n",
        "dataset_AUS = dataset[dataset['Country']=='Australia']\n",
        "df_AUS = pd.DataFrame(dataset_AUS.groupby('Date',as_index=True)['PercentOfBaseline'].mean())\n",
        "print(df_AUS)"
      ],
      "metadata": {
        "id": "Kd6ALhA6we9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mengubah Dataframe ke type float (df_US:Amerika & df_AUS: Australia)\n",
        "#dataset = df_US.values\n",
        "#dataset = dataset.astype('float32') #Mengubah nilai menjadi float\n",
        "#df_US=df_US.astype('float32')\n",
        "\n",
        "#dataset = df_AUS.values\n",
        "#dataset = dataset.astype('float32')\n",
        "df_AUS=df_AUS.astype('float')"
      ],
      "metadata": {
        "id": "30IvlPlHwe5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM menggunakan sigmoid and tanh yang sensitif terhadap nilai input sehingga harus di-normalisasi\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#dataset = scaler.fit_transform(dataset)\n",
        "df_AUS=scaler.fit_transform(df_AUS)"
      ],
      "metadata": {
        "id": "_Cvp6gD9we0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pemecahan data (untuk training & testing) tidak dapat dilakukan secara random dalam peristiwa time series\n",
        "\n",
        "#Kita bagi 2/3 atau 66% data pertama untuk training dan sisasnya 1/3 untuk testing\n",
        "#train_size = int(len(dataset) * 0.66)\n",
        "#test_size = len(dataset) - train_size\n",
        "#train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "train_size = int(len(df_AUS) * 0.66)\n",
        "test_size = len(df_AUS) - train_size\n",
        "train, test = df_AUS[0:train_size,:], df_US[train_size:len(df_US),:]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "42Hwk3UVwevz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Menyusun Dataset Training & Test dimana X adalah jumlah data 'PercentOfBaseline' pada saat(t, t-1, t-2...) \n",
        "#dan Y adalah jumlah data 'PercentOfBaseline' pada saat (t + 1).\n",
        "#(df_US:Amerika & df_AUS: Australia)\n",
        "def to_sequences(df_AUS, seq_size=1):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(df_AUS)-seq_size-1):\n",
        "        #print(i)\n",
        "        window = df_AUS[i:(i+seq_size), 0]\n",
        "        x.append(window)\n",
        "        y.append(df_AUS[i+seq_size, 0])\n",
        "        \n",
        "    return np.array(x),np.array(y)\n",
        "    \n",
        "seq_size = 10  # Number of time steps to look back \n",
        "#Larger sequences (look further back) may improve forecasting.\n",
        "\n",
        "trainX, trainY = to_sequences(train, seq_size)\n",
        "testX, testY = to_sequences(test, seq_size)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Shape of training set: {}\".format(trainX.shape))\n",
        "print(\"Shape of test set: {}\".format(testX.shape))\n",
        "#print(\"Shape of training set: {}\".format(trainY.shape))\n",
        "#print(\"Shape of test set: {}\".format(testY.shape))"
      ],
      "metadata": {
        "id": "BRvRFTUqweq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "print('Single LSTM with hidden Dense...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(None, seq_size)))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "#monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
        "#verbose=1, mode='auto', restore_best_weights=True)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Qp90bndQVcge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stacked LSTM with 1 hidden dense layer\n",
        "#reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "#\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(None, seq_size)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "bEziyKL1wemd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bidirectional LSTM\n",
        "#reshape input to be [samples, time steps, features]\n",
        "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
        "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
        "\n",
        "##For some sequence forecasting problems we may need LSTM to learn\n",
        "## sequence in both forward and backward directions\n",
        "from keras.layers import Bidirectional\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(None, seq_size)))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "UZRabtnmV36H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX.reshape((trainX.shape[0], 1, 1, 1, seq_size))\n",
        "testX = testX.reshape((testX.shape[0], 1, 1, 1, seq_size))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ConvLSTM2D(filters=64, kernel_size=(1,1), activation='relu', input_shape=(1, 1, 1, seq_size)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "BmjEFxABweh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "model.fit(trainX, trainY, validation_data=(testX, testY),\n",
        "          verbose=2, epochs=100)\n",
        "\n",
        "stop = timeit.default_timer()\n",
        "lama_eksekusi = stop - start\n",
        "print(\"Lama eksekusi: \",lama_eksekusi,\"detik\")"
      ],
      "metadata": {
        "id": "e_C9V-HqTCd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Membuat Prediksi Data Training & Test\n",
        "trainPredict = model.predict(trainX)\n",
        "testPredict = model.predict(testX)"
      ],
      "metadata": {
        "id": "QomIa0Sv0Lzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Invert predictions back to prescaled values\n",
        "#This is to compare with original input values\n",
        "#Since we used minmaxscaler we can now use scaler.inverse_transform\n",
        "#to invert the transformation.\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\n",
        "trainY = scaler.inverse_transform([trainY])\n",
        "testPredict = scaler.inverse_transform(testPredict)\n",
        "testY = scaler.inverse_transform([testY])"
      ],
      "metadata": {
        "id": "EdPx1eVFwec6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Menghitung Root Mean Squared Error (RMSE)\n",
        "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
        "print('Train Score: %.2f RMSE' % (trainScore))\n",
        "\n",
        "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
        "print('Test Score: %.2f RMSE' % (testScore))"
      ],
      "metadata": {
        "id": "PZPoSr3xweXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Menghitung Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(trainY[0], trainPredict[:,0])\n",
        "mae = mean_absolute_error(testY[0], testPredict[:,0])\n",
        "print(\"Mean Absolute Error (MAE)_Train: \", mae)\n",
        "print(\"Mean Absolute Error (MAE)_Test : \", mae)"
      ],
      "metadata": {
        "id": "YSgrGvzVQ9fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shift train predictions for plotting\n",
        "#we must shift the predictions so that they align on the x-axis with the original dataset. \n",
        "trainPredictPlot = np.empty_like(df_US)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict\n",
        "\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = np.empty_like(df_US)\n",
        "testPredictPlot[:, :] = np.nan\n",
        "testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(df_US)-1, :] = testPredict"
      ],
      "metadata": {
        "id": "m_Qo9RkSweRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot baseline and predictions\n",
        "plt.figure(figsize=(12,5), dpi=100)\n",
        "plt.plot(scaler.inverse_transform(df_US))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BX8JeamLweCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1vb5e0-_wdvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GLL8Tteax0e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Uix4D7sx0XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Kl6W3zdwx0Q9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}